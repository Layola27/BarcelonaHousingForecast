# üèòÔ∏è Proyecto de Predicci√≥n de Precios de Viviendas en Barcelona

## üìå Descripci√≥n del Proyecto

Este proyecto se centra en la construcci√≥n de un modelo de machine learning para predecir los precios de las viviendas en Barcelona. Se implementa un flujo de trabajo completo que abarca la obtenci√≥n de datos desde la API de Idealista, la unificaci√≥n de datasets, el preprocesamiento exhaustivo y el entrenamiento de un modelo XGBoost. El artefacto principal generado es un pipeline serializado que encapsula todas las transformaciones de datos y el modelo, listo para ser utilizado en una aplicaci√≥n para realizar predicciones.

## üéØ Objetivos

* Obtener datos actualizados de viviendas en Barcelona desde la API de Idealista.
* Unificar los datos nuevos con los existentes, eliminando duplicados.
* Limpiar y preprocesar los datos para prepararlos para el modelado.
* Realizar una ingenier√≠a de caracter√≠sticas avanzada para extraer informaci√≥n relevante y crear nuevas variables.
* Entrenar un modelo de machine learning preciso para predecir los precios de las viviendas.
* Guardar el pipeline completo para facilitar su uso en producci√≥n.

---

## üöÄ Caracter√≠sticas del Proyecto

* **Obtenci√≥n de Datos de la API:** Extracci√≥n automatizada de datos de viviendas desde la API de Idealista.
* **Unificaci√≥n de Datasets:** Combinaci√≥n de nuevos datos con los existentes y eliminaci√≥n de duplicados.
* **Preprocesamiento Integral:** Limpieza, formateo, imputaci√≥n de nulos y transformaci√≥n de datos.
* **Ingenier√≠a de Caracter√≠sticas Avanzada:** Creaci√≥n de caracter√≠sticas espaciales, no lineales y de interacci√≥n.
* **Modelado Predictivo:** Entrenamiento y optimizaci√≥n de un modelo XGBoost Regressor.
* **Pipeline Serializado:** Guardado de todo el flujo de preprocesamiento y el modelo en un √∫nico archivo.

---

## üõ†Ô∏è Tecnolog√≠as y Herramientas Utilizadas

| Herramienta / Lenguaje | Descripci√≥n |
|------------------------|-------------|
| **Python** | Lenguaje principal para la manipulaci√≥n de datos, llamadas a la API y modelado. |
| **Pandas** | Librer√≠a para la manipulaci√≥n y an√°lisis de datos tabulares. |
| **NumPy** | Librer√≠a para la computaci√≥n num√©rica. |
| **Requests** | Librer√≠a para realizar peticiones HTTP a la API de Idealista. |
| **Base64** | Librer√≠a para la codificaci√≥n de credenciales de la API. |
| **Geopy** | Librer√≠a para calcular distancias geod√©sicas. |
| **Scikit-learn** | Librer√≠a para el preprocesamiento de datos, clustering, PCA y modelado. |
| **XGBoost** | Librer√≠a para el modelo de Gradient Boosting. |
| **Category Encoders** | Librer√≠a para la codificaci√≥n de variables categ√≥ricas. |
| **Joblib** | Librer√≠a para serializar y guardar el pipeline completo. |
| **Google Colab** | Entorno de desarrollo en la nube utilizado para ejecutar el c√≥digo. |

---

## üß† Metodolog√≠a General

1.  **Obtenci√≥n de Datos:** El notebook `1.IdealistaAPI.ipynb` se encarga de obtener datos de viviendas desde la API de Idealista. Se autentica, define los par√°metros de b√∫squeda y guarda los resultados en archivos CSV.
2.  **Unificaci√≥n de Datasets:** El notebook `2.AgregarNuevasViviendas.ipynb` combina los nuevos datos obtenidos de la API con los datos existentes, eliminando los registros duplicados.
3.  **Preprocesamiento Inicial:** El notebook `3.PreProcesamiento.ipynb` realiza una limpieza y transformaci√≥n inicial de los datos, eliminando columnas innecesarias y extrayendo informaci√≥n de columnas JSON.
4.  **Preprocesamiento Avanzado y Modelado:** El notebook `4.ModeloExport.ipynb` realiza el preprocesamiento avanzado, la ingenier√≠a de caracter√≠sticas y el entrenamiento del modelo XGBoost. El pipeline completo se guarda en un archivo `.joblib`.

---

## üìÅ Descripci√≥n de los Notebooks

* **`1.IdealistaAPI.ipynb`:**
    * Obtiene datos de la API de Idealista.
    * Realiza la autenticaci√≥n y las peticiones a la API.
    * Guarda los datos en archivos CSV.
* **`2.AgregarNuevasViviendas.ipynb`:**
    * Unifica los nuevos datos con los existentes.
    * Elimina los duplicados.
    * Guarda el dataset unificado.
* **`3.PreProcesamiento.ipynb`:**
    * Realiza el preprocesamiento inicial de los datos.
    * Elimina columnas innecesarias.
    * Extrae informaci√≥n de columnas JSON.
* **`4.ModeloExport.ipynb`:**
    * Realiza el preprocesamiento avanzado.
    * Implementa la ingenier√≠a de caracter√≠sticas.
    * Entrena el modelo XGBoost.
    * Guarda el pipeline completo.

---

Este README proporciona una visi√≥n general del proyecto, su prop√≥sito, la metodolog√≠a seguida y las herramientas utilizadas. Los notebooks detallan cada etapa del proceso, desde la obtenci√≥n de los datos hasta la generaci√≥n del modelo predictivo.
