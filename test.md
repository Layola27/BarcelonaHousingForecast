# BarcelonaHousingForecast

## Descripci贸n del Proyecto

Este proyecto tiene como objetivo principal la construcci贸n de un modelo de machine learning capaz de predecir los precios de las viviendas en la ciudad de Barcelona. Para lograrlo, se abarcan diversas etapas clave, desde la **obtenci贸n de datos** actualizados hasta el **preprocesamiento** exhaustivo de los mismos, el entrenamiento de un modelo **XGBoost** y la creaci贸n de un **pipeline serializado** listo para su puesta en producci贸n.

## Objetivos

Los objetivos espec铆ficos del proyecto son:

* Obtenci贸n de datos actualizados de la API de Idealista.
* Unificaci贸n y limpieza de datasets, incluyendo la eliminaci贸n de duplicados.
* Limpieza y preprocesamiento detallado de los datos.
* Ingenier铆a de caracter铆sticas avanzada para mejorar el rendimiento del modelo.
* Entrenamiento de un modelo preciso de machine learning para la predicci贸n de precios.
* Guardado del pipeline completo (preprocesamiento y modelo) para facilitar su uso en entornos de producci贸n.

## Caracter铆sticas del Proyecto

Las principales caracter铆sticas implementadas en este proyecto incluyen:

* **Obtenci贸n automatizada de datos**: Conexi贸n con la API de Idealista para la extracci贸n de informaci贸n reciente sobre viviendas.
* **Unificaci贸n de datasets**: Consolidaci贸n de datos hist贸ricos y nuevos, con un proceso robusto para la eliminaci贸n de duplicados.
* **Preprocesamiento integral**: Abarca limpieza de datos, formateo, imputaci贸n de valores faltantes y transformaciones necesarias.
* **Ingenier铆a de caracter铆sticas avanzada**: Creaci贸n de nuevas variables predictivas, incluyendo caracter铆sticas espaciales (distancias a puntos de inter茅s), no lineales y de interacci贸n entre variables existentes.
* **Modelado predictivo**: Implementaci贸n de un modelo XGBoost Regressor, conocido por su alto rendimiento en problemas de regresi贸n.
* **Pipeline serializado**: El flujo completo de preprocesamiento y el modelo entrenado se guardan en un archivo `.joblib` para su f谩cil reutilizaci贸n y despliegue.

## Tecnolog铆as y Herramientas Utilizadas 

Este proyecto aprovecha un conjunto de potentes bibliotecas y herramientas de Python para cubrir todo el ciclo de vida del desarrollo de un modelo de Machine Learning, desde la adquisici贸n de datos hasta la serializaci贸n del modelo para producci贸n. A continuaci贸n, se detalla cada componente, su prop贸sito y c贸mo contribuye a los aspectos m谩s avanzados del proyecto:

| Tecnolog铆a / Herramienta | Logo (Sugerencia)        | Prop贸sito Principal                                   | Contribuci贸n Espec铆fica / T茅cnicas Avanzadas Aplicadas                                                                                                                                                                                                                                                                                         |
| :----------------------- | :-----------------------: | :--------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Python** |       ![Python]()         | Lenguaje de programaci贸n principal                     | Orquestaci贸n de todo el flujo de trabajo, scripting para automatizaci贸n, y la base sobre la cual todas las dem谩s librer铆as operan. Su sintaxis clara y el vasto ecosistema de librer铆as lo hacen ideal para Data Science.                                                                                                       |
| **Pandas** |       ![Pandas]()         | Manipulaci贸n y an谩lisis de datos tabulares             | **Ingesta de datos** (desde CSVs, resultados de API), **limpieza exhaustiva** (manejo de nulos con estrategias espec铆ficas, correcci贸n de tipos de datos, detecci贸n de outliers), **transformaci贸n de datos** (pivoting, merging, reshaping), y **an谩lisis exploratorio de datos (EDA)** fundamental para entender las relaciones. |
| **NumPy** |        ![NumPy]()         | Computaci贸n num茅rica eficiente                       | Base para Pandas y Scikit-learn. Utilizado para operaciones vectorizadas de alta velocidad, manipulaci贸n de arrays multidimensionales, y funciones matem谩ticas esenciales para el preprocesamiento y la ingenier铆a de caracter铆sticas.                                                                                   |
| **Requests** |      ![Requests]()       | Peticiones HTTP a la API                             | Interacci贸n con la API de Idealista para la **extracci贸n automatizada y program谩tica de datos**. Gesti贸n de sesiones, manejo de errores HTTP y timeouts para robustecer la adquisici贸n de datos.                                                                                                                            |
| **Base64** |       ![Base64]()         | Codificaci贸n de credenciales                         | Utilizado para **codificar de forma segura las credenciales (API\_KEY, API\_SECRET)** antes de enviarlas en las cabeceras de autorizaci贸n de las peticiones a la API de Idealista, a帽adiendo una capa b谩sica de seguridad.                                                                                               |
| **Geopy** |        ![Geopy]()         | C谩lculo de distancias geod茅sicas                     | **Ingenier铆a de caracter铆sticas espaciales avanzadas**: c谩lculo de distancias exactas entre las propiedades y puntos de inter茅s clave en Barcelona (e.g., centro de la ciudad, playas, parques, estaciones de transporte), lo cual puede ser un predictor muy potente del precio.                                           |
| **Scikit-learn** |     ![Scikit-learn]()     | Ecosistema de Machine Learning                       | Utilizado extensivamente para: <br> - **Preprocesamiento**: `SimpleImputer` (imputaci贸n de nulos), `StandardScaler`/`MinMaxScaler` (escalado de caracter铆sticas), `PowerTransformer` (transformaciones no lineales). <br> - **Ingenier铆a de Caracter铆sticas**: `PCA` (An谩lisis de Componentes Principales) para reducci贸n de dimensionalidad o creaci贸n de features latentes, `KBinsDiscretizer` (discretizaci贸n de variables continuas). <br> - **Clustering**: `KMeans` podr铆a usarse para segmentar propiedades o barrios como una caracter铆stica adicional. <br> - **Selecci贸n de Modelos**: `train_test_split`, `cross_val_score` para validaci贸n cruzada robusta. <br> - **M茅tricas de Evaluaci贸n**: `mean_squared_error`, `r2_score` para evaluar el rendimiento del modelo de regresi贸n. <br> - **Pipelines**: Creaci贸n de `Pipeline` y `ColumnTransformer` para organizar y aplicar secuencialmente transformaciones complejas y espec铆ficas por tipo de columna, asegurando la reproducibilidad y evitando fugas de datos. |
| **XGBoost** |      ![XGBoost]()        | Modelo de Gradient Boosting de alto rendimiento        | Implementaci贸n del `XGBRegressor`. **T茅cnicas avanzadas**: <br> - Manejo nativo de valores faltantes. <br> - Regularizaci贸n (L1/L2) para prevenir el sobreajuste. <br> - Optimizaci贸n mediante validaci贸n cruzada y b煤squeda de hiperpar谩metros (e.g., con `GridSearchCV` o `RandomizedSearchCV` de Scikit-learn). <br> - `Early Stopping` para encontrar el n煤mero 贸ptimo de estimadores. <br> - An谩lisis de **importancia de caracter铆sticas** (`feature_importances_`) para interpretar el modelo. |
| **Category Encoders** |      ![CatEnc]()        | Codificaci贸n de variables categ贸ricas                | Proporciona una variedad de **estrategias de codificaci贸n para variables categ贸ricas** m谩s all谩 del One-Hot Encoding, como `TargetEncoder`, `LeaveOneOutEncoder`, o `HashingEncoder`, especialmente 煤tiles para caracter铆sticas con alta cardinalidad o cuando se busca capturar la relaci贸n entre la variable categ贸rica y la variable objetivo. |
| **Joblib** |       ![Joblib]()         | Serializaci贸n eficiente de objetos Python            | Utilizado para **guardar (serializar) el pipeline de Scikit-learn completo** (que incluye todos los pasos de preprocesamiento y el modelo XGBoost entrenado) en un 煤nico archivo `.joblib`. Esto permite una f谩cil carga y reutilizaci贸n del modelo en entornos de producci贸n o para inferencias futuras sin necesidad de reentrenar. Es eficiente con objetos que contienen grandes arrays de NumPy. |
| **Google Colab** |   ![Google Colab]()     | Entorno de desarrollo basado en la nube (Jupyter)    | Proporciona un **entorno interactivo** con acceso gratuito a GPUs/TPUs (煤til para acelerar el entrenamiento de modelos como XGBoost), preinstalaci贸n de librer铆as comunes, y f谩cil colaboraci贸n e integraci贸n con Google Drive para el almacenamiento de datos y modelos.                                               |

*Nota: Los placeholders `![Logo X]()` indican d贸nde podr铆as insertar los logos de las tecnolog铆as si deseas a帽adirlos directamente a tu README.md en GitHub (por ejemplo, subi茅ndolos a una carpeta `.github/images` en tu repositorio y enlaz谩ndolos, o usando URLs de servicios de badges/iconos).*

### Diagrama del Flujo de Trabajo Tecnol贸gico

```mermaid
graph TD
    A[Idealista API] -- Peticiones HTTP con<br/>Requests, Base64 (Credenciales) --> B(Datos Crudos en CSV);
    B -- Carga y Limpieza Inicial con<br/>Pandas & NumPy --> C{An谩lisis Exploratorio de Datos (EDA)};
    C -- Preparaci贸n para Modelado --> D_Pipeline["Pipeline de Preprocesamiento y Modelado (Scikit-learn)"];

    subgraph D_Pipeline
        direction LR
        D1[Entrada: Datos Limpios] --> D2{Imputaci贸n de Nulos<br/>(SimpleImputer)};
        D2 --> D3{Escalado de Caracter铆sticas<br/>(StandardScaler/MinMaxScaler)};
        D3 --> D4{Codificaci贸n de Categ贸ricas<br/>(Category Encoders: TargetEncoder, etc.)};
        D4 --> D5{Ingenier铆a de Caracter铆sticas Avanzada<br/>(Geopy para distancias,<br/>PCA si aplica, Transformaciones)};
        D5 --> D6[Modelo Predictivo<br/>(XGBoost: XGBRegressor)];
    end

    D_Pipeline -- Entrenamiento y Optimizaci贸n --> E{Validaci贸n Cruzada y<br/>Ajuste de Hiperpar谩metros};
    E -- Pipeline Entrenado --> F[Serializaci贸n del Pipeline Completo<br/>(Joblib -> .joblib)];

    G((Entorno de Desarrollo<br/>Google Colab<br/>Lenguaje: Python));

    classDef apiNode fill:#87CEEB,stroke:#333,stroke-width:2px,color:#000;
    classDef dataNode fill:#90EE90,stroke:#333,stroke-width:2px,color:#000;
    classDef processNode fill:#FFD700,stroke:#333,stroke-width:2px,color:#000;
    classDef modelNode fill:#FFA07A,stroke:#333,stroke-width:2px,color:#000;
    classDef outputNode fill:#DDA0DD,stroke:#333,stroke-width:2px,color:#000;
    classDef envNode fill:#E6E6FA,stroke:#333,stroke-width:2px,color:#000;

    class A apiNode;
    class B,C dataNode;
    class D2,D3,D4,D5,E processNode;
    class D6 modelNode;
    class F outputNode;
    class G envNode;
