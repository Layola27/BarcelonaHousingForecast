{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1O7U-_e-9Nqdno8DUqIuWimdri37NLCGb",
      "authorship_tag": "ABX9TyOWKMLeURjjUrtkzJ6Mtz+y"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Instala category_encoders (solo hace falta una vez por sesión)\n",
        "!pip install category_encoders\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8J6D13Dlilv",
        "outputId": "6a02ba58-e430-4c6c-9323-b2cce18a69d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.11/dist-packages (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.14.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE 1: Importar librerías y montar Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from geopy.distance import geodesic\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, SplineTransformer, PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "import category_encoders as ce\n",
        "import joblib\n",
        "\n",
        "# Semilla global\n",
        "RNG = 42\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJngES45ZC8k",
        "outputId": "7c965dbf-8aff-416c-f221-cea5a30c74ce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE 2: Carga del CSV y selección de columnas relevantes\n",
        "file_path = '/content/drive/MyDrive/Dataset Idealista/pisosBarcelona-21-04-2025-clean.csv'\n",
        "df = pd.read_csv(file_path, encoding='latin1')\n",
        "\n",
        "relevant_cols = [\n",
        "    'price','size','rooms','bathrooms','floor','hasLift','exterior',\n",
        "    'propertyType','status','numPhotos','latitude','longitude',\n",
        "    'hasParking','isParkingIncludedInPrice'\n",
        "]\n",
        "df_model = df[relevant_cols].copy()\n",
        "print(f\"Cargados {df_model.shape[0]} registros y {df_model.shape[1]} columnas\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLs3MIe2ZEFN",
        "outputId": "c051bd22-93d6-4d92-8d05-31558f03ec3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargados 8478 registros y 14 columnas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE 3: Limpieza y formato sin chained-assignment\n",
        "df_model = df_model.copy()\n",
        "\n",
        "# Floor → numérico (bj=0, en=0.5, ss=-1), imputar mediana\n",
        "floor_map = {'bj':0.0,'en':0.5,'ss':-1.0}\n",
        "df_model['floor'] = pd.to_numeric(\n",
        "    df_model['floor'].replace(floor_map),\n",
        "    errors='coerce'\n",
        ").fillna(df_model['floor'].map(floor_map).median())\n",
        "\n",
        "# Exterior → 1/0, imputar moda\n",
        "df_model['exterior'] = pd.to_numeric(\n",
        "    df_model['exterior'].replace({'Unknown':np.nan, True:1, False:0}),\n",
        "    errors='coerce'\n",
        ").fillna(df_model['exterior'].mode()[0]).astype(int)\n",
        "\n",
        "# hasLift → 1/0, imputar moda\n",
        "df_model['hasLift'] = df_model['hasLift'].fillna(df_model['hasLift'].mode()[0]).astype(int)\n",
        "\n",
        "# status → rellenar nulos con 'Unknown'\n",
        "df_model['status'] = df_model['status'].fillna('Unknown')\n",
        "\n",
        "# parking_status combinada + drop originales\n",
        "conds = [\n",
        "    (df_model['hasParking']==1)&(df_model['isParkingIncludedInPrice']==1),\n",
        "    (df_model['hasParking']==1)&(df_model['isParkingIncludedInPrice']==0),\n",
        "    (df_model['hasParking']==0)\n",
        "]\n",
        "choices = ['Included','Optional','None']\n",
        "df_model['parking_status'] = np.select(conds, choices, default='Unknown')\n",
        "df_model.drop(['hasParking','isParkingIncludedInPrice'], axis=1, inplace=True)\n",
        "\n",
        "# Flags de nulos\n",
        "for c in ['size','rooms','bathrooms','latitude','longitude']:\n",
        "    df_model[f'isna_{c}'] = df_model[c].isna().astype(int)\n",
        "\n",
        "# Imputar numéricos con mediana\n",
        "for c in ['size','rooms','bathrooms','latitude','longitude']:\n",
        "    df_model[c] = df_model[c].fillna(df_model[c].median())\n",
        "\n",
        "print(\"Nulls remanentes:\\n\", df_model.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bARSMfMEeI-V",
        "outputId": "34fc31d3-8a30-4dd1-ce4d-b83a2632af9c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nulls remanentes:\n",
            " price             0\n",
            "size              0\n",
            "rooms             0\n",
            "bathrooms         0\n",
            "floor             0\n",
            "hasLift           0\n",
            "exterior          0\n",
            "propertyType      0\n",
            "status            0\n",
            "numPhotos         0\n",
            "latitude          0\n",
            "longitude         0\n",
            "parking_status    0\n",
            "isna_size         0\n",
            "isna_rooms        0\n",
            "isna_bathrooms    0\n",
            "isna_latitude     0\n",
            "isna_longitude    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-0f1eec2f8236>:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_model['exterior'].replace({'Unknown':np.nan, True:1, False:0}),\n",
            "<ipython-input-8-0f1eec2f8236>:18: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_model['hasLift'] = df_model['hasLift'].fillna(df_model['hasLift'].mode()[0]).astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE 4: Ingeniería espacial + cluster avg price\n",
        "# 4.1 Distancias a POIs\n",
        "pois = {\n",
        "  'Catalunya':(41.3874,2.1700),\n",
        "  'Barceloneta':(41.3790,2.1885),\n",
        "  'Sants':(41.3793,2.1400),\n",
        "  'CampNou':(41.3809,2.1228),\n",
        "  'ParcGuell':(41.4145,2.1527)\n",
        "}\n",
        "coords = list(zip(df_model['latitude'],df_model['longitude']))\n",
        "for name, loc in pois.items():\n",
        "    df_model[f'DistKm_{name}'] = [\n",
        "        geodesic(loc, xy).km for xy in coords\n",
        "    ]\n",
        "\n",
        "# 4.2 Clustering geográfico + PCA(1)\n",
        "geo = StandardScaler().fit_transform(df_model[['latitude','longitude']])\n",
        "kmeans = KMeans(n_clusters=8, random_state=RNG, n_init='auto').fit(geo)\n",
        "df_model['geo_cluster'] = kmeans.labels_\n",
        "\n",
        "pca1 = PCA(n_components=1, random_state=RNG).fit_transform(geo)\n",
        "df_model['geo_pca1'] = pca1.flatten()\n",
        "\n",
        "# 4.3 Precio medio log por cluster\n",
        "df_model['price_log'] = np.log1p(df_model['price'])\n",
        "cluster_avg = df_model.groupby('geo_cluster')['price_log'].transform('mean')\n",
        "df_model['cluster_avg_logprice'] = cluster_avg\n"
      ],
      "metadata": {
        "id": "lqmme__BeQmj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE 5: Codificación objetivo suavizada (Target Encoding)\n",
        "te_cols = ['propertyType','status','parking_status']\n",
        "te = ce.TargetEncoder(cols=te_cols, smoothing=10)\n",
        "df_model[te_cols] = te.fit_transform(df_model[te_cols], df_model['price_log'])\n"
      ],
      "metadata": {
        "id": "BDK4kJy3eTj7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE 6: Splines y polinomios para capturar no linealidad\n",
        "# 6.1 Spline sobre size y distancias\n",
        "spline = SplineTransformer(degree=3, n_knots=5, include_bias=False)\n",
        "spline_feats = spline.fit_transform(df_model[['size'] + [f'DistKm_{p}' for p in pois]])\n",
        "spline_names = spline.get_feature_names_out(['size'] + [f'DistKm_{p}' for p in pois])\n",
        "df_splines = pd.DataFrame(spline_feats, columns=spline_names, index=df_model.index)\n",
        "df_model = pd.concat([df_model, df_splines], axis=1)\n",
        "\n",
        "# 6.2 Interacciones de grado 2 (sin cuadrados)\n",
        "num_base = ['size','rooms','bathrooms','floor','numPhotos',\n",
        "            'geo_pca1','cluster_avg_logprice']\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
        "X_poly = poly.fit_transform(df_model[num_base])\n",
        "poly_names = poly.get_feature_names_out(num_base)\n",
        "df_poly = pd.DataFrame(X_poly, columns=poly_names, index=df_model.index)\n",
        "# añadimos solo las interacciones nuevas\n",
        "new_ints = [c for c in poly_names if '*' in c]\n",
        "df_model = pd.concat([df_model, df_poly[new_ints]], axis=1)\n"
      ],
      "metadata": {
        "id": "zN0OLAH8eVNC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE 7: Filtrado de outliers sobre price_log (1–99 percentil)\n",
        "y = df_model['price_log']\n",
        "low, high = y.quantile([0.01,0.99])\n",
        "mask = y.between(low, high)\n",
        "df_model = df_model[mask]\n",
        "print(\"Registros tras filtrar outliers:\", df_model.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwX3YejBeXFJ",
        "outputId": "7e6c8c98-326e-4ab2-aea3-e43c8d140637"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registros tras filtrar outliers: 8309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE 8: Train/Test split y escalado\n",
        "X = df_model.drop(columns=['price','price_log'])\n",
        "y = df_model['price_log']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=RNG\n",
        ")\n",
        "\n",
        "# Escalado solo numéricos\n",
        "num_cols = X_train.select_dtypes(include=['int64','float64']).columns\n",
        "scaler = StandardScaler().fit(X_train[num_cols])\n",
        "X_train[num_cols] = scaler.transform(X_train[num_cols])\n",
        "X_test [num_cols] = scaler.transform(X_test [num_cols])\n",
        "\n",
        "print(\"Train/Test shapes:\", X_train.shape, X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apMDtjXUeZNZ",
        "outputId": "78d3ba7b-2ac1-468a-e7eb-101c3cb3284e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/Test shapes: (6647, 61) (1662, 61)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE 9: RandomizedSearchCV XGBoost con regularización avanzada\n",
        "param_dist = {\n",
        "    'n_estimators':     [100,200,500],\n",
        "    'learning_rate':    [0.01,0.05,0.1],\n",
        "    'max_depth':        [3,5,7],\n",
        "    'subsample':        [0.7,0.9,1.0],\n",
        "    'colsample_bytree': [0.7,0.9,1.0],\n",
        "    'reg_alpha':        [0, 0.01, 0.1, 1],\n",
        "    'reg_lambda':       [0.5, 1, 5, 10]\n",
        "}\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    random_state=RNG,\n",
        "    n_jobs=-1,\n",
        "    tree_method='hist'      # más rápido en dataset grande\n",
        ")\n",
        "\n",
        "rand_search = RandomizedSearchCV(\n",
        "    xgb_model, param_dist,\n",
        "    n_iter=40, cv=5,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    random_state=RNG, n_jobs=-1, verbose=2,\n",
        "    error_score='raise'\n",
        ")\n",
        "rand_search.fit(X_train, y_train)\n",
        "best_model = rand_search.best_estimator_\n",
        "print(\"Mejores parámetros:\", rand_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en7gzqtAefw7",
        "outputId": "13c70fce-933c-4c46-e4f7-c297acaf7231"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
            "Mejores parámetros: {'subsample': 0.7, 'reg_lambda': 0.5, 'reg_alpha': 0.1, 'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE 10: Evaluación final y guardado del pipeline\n",
        "# Predicción en escala original\n",
        "y_pred_log = best_model.predict(X_test)\n",
        "y_test_orig = np.expm1(y_test)\n",
        "y_pred_orig = np.expm1(y_pred_log)\n",
        "\n",
        "mae  = mean_absolute_error(y_test_orig, y_pred_orig)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
        "r2   = r2_score(y_test_orig, y_pred_orig)\n",
        "\n",
        "print(f\"MAE   : {mae:,.2f} €\")\n",
        "print(f\"RMSE  : {rmse:,.2f} €\")\n",
        "print(f\"R²    : {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcMzsNkXeb7B",
        "outputId": "78855393-cd53-46eb-ab01-6f46a500281e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE   : 67,452.74 €\n",
            "RMSE  : 125,739.32 €\n",
            "R²    : 0.8595\n",
            "Pipeline guardado en Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Definir carpeta de destino\n",
        "import os\n",
        "save_dir = '/content/drive/MyDrive/ModelosIdealista'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# 3) Serializar pipeline completo\n",
        "import joblib\n",
        "\n",
        "pipeline = {\n",
        "    'scaler'        : scaler,               # StandardScaler ajustado\n",
        "    'target_encoder': te,                   # TargetEncoder ajustado\n",
        "    'xgb_model'     : best_model,           # XGBRegressor con mejores parámetros\n",
        "    'feature_order' : X.columns.tolist(),   # Orden de columnas/variables del modelo\n",
        "    'num_cols'      : num_cols.tolist(),    # Lista de columnas numéricas\n",
        "    'te_cols'       : te_cols               # Lista de columnas categóricas target-encoded\n",
        "}\n",
        "\n",
        "joblib.dump(pipeline, os.path.join(save_dir, 'pipeline_idealista.joblib'))\n",
        "\n",
        "print(f\"✅ Pipeline exportado correctamente en: {save_dir}/pipeline_idealista.joblib\")\n"
      ],
      "metadata": {
        "id": "aizEltBhktE2",
        "outputId": "e857fbe1-3e1a-429f-b6cc-7597f8d97e7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Pipeline exportado correctamente en: /content/drive/MyDrive/ModelosIdealista/pipeline_idealista.joblib\n"
          ]
        }
      ]
    }
  ]
}